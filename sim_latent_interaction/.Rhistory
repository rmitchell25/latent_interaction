corr_Xs <- .20
rsq_baseline <- .13
rsq_prod <- c(0,0.03,0.07)
XtoD_split <- 1
simp_slopes <- 'diffuse' # interaction pattern is concentrated vs. diffuse
group_probs <- rbind(c(.34, .33, .33),
c(.40, .40, .20),
c(.60, .20, .20))
sample_size <- c(seq(100,400, by = 50),500,1000)
loading_size <- c(.5,.8)
num_loadings <- c(6,12)
############################################################
# function to solve for latent response variable means
############################################################
solve_mu <- function(mu, group_probs) {
sigma <- matrix(c(1,.5,.5,1), nrow = 2)
# compute probability c = 1 (reference) as area below 0
lower <- rep(-Inf, (length(mu) + 1) - 1); upper <- rep(0, (length(mu) + 1) - 1)
prob1 <- pmvnorm(lower, upper, mu, corr = NULL, sigma)
# transform mean vector and covariance matrix
trans_matrix <- matrix(0, ncol = (length(mu) + 1) - 1, nrow = (length(mu) + 1) - 1)
trans_matrix[,1] <- -1; trans_matrix[2,2] <- 1
mu_trans <- as.vector(trans_matrix %*% (mu))
sigma_trans <- trans_matrix %*% sigma %*% t(trans_matrix)
# compute probability c = 2 as area below 0 in the transformed space
lower <- rep(-Inf, (length(mu) + 1) - 1); upper <- rep(0, (length(mu) + 1) - 1)
prob2 <- pmvnorm(lower, upper, mu_trans, corr = NULL, sigma_trans)
# transformation matrix, mean vector, covariance matrix for c = 3
trans_matrix <- matrix(0, ncol = (length(mu) + 1) - 1, nrow = (length(mu) + 1) - 1)
trans_matrix[,2] <- -1; trans_matrix[2,1] <- 1
mu_trans <- as.vector(trans_matrix %*% (mu))
sigma_trans <- trans_matrix %*% sigma %*% t(trans_matrix)
# compute probability c = 3 as area below 0 in the transformed space
lower <- rep(-Inf, (length(mu) + 1) - 1); upper <- rep(0, (length(mu) + 1) - 1)
prob3 <- pmvnorm(lower, upper, mu_trans, corr = NULL, sigma_trans)
# loss function: sum of square differences between target and current values
return(sum((c(prob1, prob2, prob3) - group_probs)^2))
}
############################################################
# # function to obtain predictor covariance matrix
############################################################
solve_cov <- function(muX){
sigma <- matrix(corr_Xs, nrow = 3, ncol = 3)
diag(sigma) <- 1; sigma[2,1] <- sigma[1,2] <- .5
coding <- 'dummy'
N <- 10000000
Xs <- rmvnorm(N,muX,sigma)
nomX <- ifelse(Xs[,1] < 0 & Xs[,2] < 0, 1, 999)
nomX <- ifelse(Xs[,1] > 0 & Xs[,1] > Xs[,2], 2, nomX)
nomX <- ifelse(Xs[,2] > 0 & Xs[,2] > Xs[,1], 3, nomX)
if(coding == 'dummy'){
C2 <- ifelse(nomX == '2', 1, 0)
C3 <- ifelse(nomX == '3', 1, 0)
}
if(coding == 'effect'){
C2 <- ifelse(nomX == "1", -1, ifelse(nomX == "2", 1, 0))
C3 <- ifelse(nomX == "1", -1, ifelse(nomX == "3", 1, 0))
}
code_data <- cbind(C2,C3,Xs[,3],C2*Xs[,3],C3*Xs[,3])
stats_CXs <- rbind(colMeans(code_data),cov(code_data))
return(stats_CXs)
}
############################################################
# function to solve for slopes
############################################################
solve_slopes <- function(slopes, statsX, rsq_baseline, rsq_prod){
# slopes <- c(0.13073646,0.13208590,0.18246931,0.06743022,0.13484283)
# statsX = stats_CXs[[1]]
# muX = statsX[1,]
# covX = statsX[-1,]
# rsq_baseline = rsq_baseline[1]
# rsq_prod = rsq_prod[1]
# check whether slopes are positive
if(any(slopes <= 0)) return(1e10)
# extract predictor means and covariance matrix
muX <- statsX[1, ]
covX <- statsX[-1, ]
num_vars <- nrow(covX) + 1
# construct beta and psi matrices
beta_mat <- psi_mat <- matrix(0, nrow = num_vars, ncol = num_vars)
beta_mat[num_vars, 1:(num_vars - 1)] <- slopes
psi_mat[1:(num_vars - 1), 1:(num_vars - 1)] <- covX
# compute the residual variance and make sure it is positive
resvar <- varY - (slopes %*% covX %*% slopes)
if(!is.finite(resvar) || resvar <= 0){
return(1e10)
}
psi_mat[num_vars, num_vars] <- resvar
# solve for the overall mean vector and covariance matrix
inv_mat <- solve(diag(num_vars) - beta_mat)
mu_all <- inv_mat %*% c(muX, muY)
cov_all <- inv_mat %*% psi_mat %*% t(inv_mat)
# assign row/column names
row.names(mu_all) <- c(paste0("predictor ", 1:(num_vars-1)), "outcome")
colnames(cov_all) <- row.names(cov_all) <- c(paste0("predictor ", 1:(num_vars-1)), "outcome")
# target r-square values
rsq_tot_target <- rsq_baseline + rsq_prod
rsq_X_target <- XtoD_split * rsq_baseline
rsq_codes_target <- rsq_baseline - rsq_X_target
rsq_cha_target <- rsq_prod
# current R-square values from covariance matrix
rsq_tot_current <- (cov_all[1:(num_vars-1), num_vars] %*%
solve(cov_all[1:(num_vars-1), 1:(num_vars-1)]) %*%
cov_all[num_vars, 1:(num_vars-1)]) / varY
rsq_codes_X_current <- (cov_all[1:3, num_vars] %*%
solve(cov_all[1:3, 1:3]) %*%
cov_all[num_vars, 1:3]) / varY
rsq_codes_current <- (cov_all[1:2, num_vars] %*%
solve(cov_all[1:2, 1:2]) %*%
cov_all[num_vars, 1:2]) / varY
rsq_X_current <- rsq_codes_X_current - rsq_codes_current
rsq_cha_current <- rsq_tot_current - rsq_codes_X_current
# interaction slope difference
int_ratio <- slopes[5] / slopes[4]
if(simp_slopes == "concentrated"){pop_ratio <- 1}
if(simp_slopes == "diffuse"){pop_ratio <- 2}
# form target and current vectors
target_vec <- c(rsq_tot_target, rsq_X_target, rsq_codes_target, rsq_cha_target, pop_ratio)
current_vec <- c(rsq_tot_current, rsq_X_current, rsq_codes_current, rsq_cha_current, int_ratio)
# loss function: sum of squared differences.
loss <- sum((current_vec - target_vec)^2)
return(loss)
}
############################################################
# function to summarize realized r-square values
############################################################
summarize_rsq <- function(slopes, statsX, rsq_baseline, rsq_prod, probs, start) {
# extract predictor means and covariance matrix
muX <- statsX[1, ]
covX <- statsX[-1, ]
num_vars <- nrow(covX) + 1
# construct beta and psi matrices
beta_mat <- psi_mat <- matrix(0, nrow = num_vars, ncol = num_vars)
beta_mat[num_vars, 1:(num_vars - 1)] <- slopes
psi_mat[1:(num_vars - 1), 1:(num_vars - 1)] <- covX
# compute the residual variance
resvar <- varY - (slopes %*% covX %*% slopes)
psi_mat[num_vars, num_vars] <- resvar
# solve for the overall mean vector and covariance matrix
inv_mat <- solve(diag(num_vars) - beta_mat)
mu_all <- inv_mat %*% c(muX, muY)
cov_all <- inv_mat %*% psi_mat %*% t(inv_mat)
# assign row/column names
row.names(mu_all) <- c(paste0("predictor ", 1:(num_vars-1)), "outcome")
colnames(cov_all) <- row.names(cov_all) <- c(paste0("predictor ", 1:(num_vars-1)), "outcome")
# target r-square values
rsq_tot_target <- rsq_baseline + rsq_prod
rsq_X_target <- XtoD_split * rsq_baseline
rsq_codes_target <- rsq_baseline - rsq_X_target
rsq_cha_target <- rsq_prod
# current R-square values from covariance matrix
rsq_tot_current <- (cov_all[1:(num_vars-1), num_vars] %*%
solve(cov_all[1:(num_vars-1), 1:(num_vars-1)]) %*%
cov_all[num_vars, 1:(num_vars-1)]) / varY
rsq_codes_X_current <- (cov_all[1:3, num_vars] %*%
solve(cov_all[1:3, 1:3]) %*%
cov_all[num_vars, 1:3]) / varY
rsq_codes_current <- (cov_all[1:2, num_vars] %*%
solve(cov_all[1:2, 1:2]) %*%
cov_all[num_vars, 1:2]) / varY
rsq_X_current <- rsq_codes_X_current - rsq_codes_current
rsq_cha_current <- rsq_tot_current - rsq_codes_X_current
# interaction slope difference
int_ratio <- slopes[5] / slopes[4]
if(simp_slopes == "concentrated"){pop_ratio <- 1}
if(simp_slopes == "diffuse"){pop_ratio <- 2}
# form target and current vectors.
target_vec <- c(rsq_tot_target, rsq_codes_target, rsq_X_target, rsq_cha_target, pop_ratio)
current_vec <- round(c(rsq_tot_current, rsq_codes_current, rsq_X_current, rsq_cha_current, int_ratio),3)
summary_table <- data.frame(
GrpProbs = probs,
RsqBase = rsq_baseline,
RsqProd = rsq_prod,
Starting_Val = start,                                                                 ############
Component = c("Total R^2", "Codes R^2", "X R^2", "Change R^2", "Interaction Ratio"),
Target = target_vec,
Realized = current_vec,
AbsDiff = abs(target_vec - current_vec)
)
# print(summary_table)
invisible(summary_table)
}
############################################################
# solve for latent predictor means
# get predictor means covariance matrices
############################################################
lat_means <- list()
stats_CXs <- list()
# solve predictor means and covariance matrices for each group size condition
for(g in 1:3){
print(paste0('computing large-N predictor covariance matrix for group ', g))
# latent response variable means
lat_means[[g]] <- c(optim(c(0,0), solve_mu, group_probs = group_probs[g,], method = "BFGS")$par,0)
# code variable means and covariance matrix
stats_CXs[[g]] <- solve_cov(lat_means[[g]]) # cbind(C2,C3,Xs[,3],C2*Xs[,3],C3*Xs[,3])
}
############################################################
# solve for predictor slopes and graph
############################################################
optim_results <- NULL
starting <-  0.115
for(g in 1:3){
for(p in 1:length(rsq_prod)){
condition_name <- paste0('group probs = (', paste(group_probs[g,], collapse = ", "),'), product rsq = ',rsq_prod[p], " varY = ", varY, " , start = ",starting)
# solve for slopes
result <- optim(rep(starting, 5), solve_slopes,
statsX = stats_CXs[[g]],
rsq_baseline = rsq_baseline,
rsq_prod = rsq_prod[p],
method = "BFGS",
control = list(maxit = 5000, reltol = 1e-8))
optim_results <- rbind(optim_results, c(g,rsq_baseline,rsq_prod[p],varY,result$convergence,result$value,round(result$par,3)))
}
}
colnames(optim_results) <- c('group','rsq_base','rsq_prod','varY','conv_status','loss_fun','b1','b2','b3','b4','b5')
optim_results <- as.data.frame(optim_results)
############################################################
# generate structural portion of model
############################################################
# Example simulation
group <- 1
prod <- .03
slopes_opt <- optim_results[optim_results$group == group & optim_results$rsq_prod == prod,7:11]
colnames(slopes_opt)<-NULL
slopes_opt <- as.numeric(slopes_opt)
muX <- lat_means[[group]]
sigma <- matrix(corr_Xs, nrow = 3, ncol = 3)
diag(sigma) <- 1; sigma[2,1] <- sigma[1,2] <- .5
N <- 10000000
Xs <- rmvnorm(N,muX,sigma)
nomX <- ifelse(Xs[,1] < 0 & Xs[,2] < 0, 1, 999)
nomX <- ifelse(Xs[,1] > 0 & Xs[,1] > Xs[,2], 2, nomX)
nomX <- ifelse(Xs[,2] > 0 & Xs[,2] > Xs[,1], 3, nomX)
# summarytools::freq(nomX)
C2 <- ifelse(nomX == '2', 1, 0)
C3 <- ifelse(nomX == '3', 1, 0)
code_data <- cbind(C2,C3,Xs[,3],C2*Xs[,3],C3*Xs[,3])
Yhat <- code_data %*% slopes_opt
resid_var <- varY - var(Yhat)
eps <- rnorm(N, 0, sqrt(resid_var))
Y <- Yhat + eps
data <- as.data.frame(cbind(code_data,Y))
colnames(data) <- c("C2", "C3", "X", "C2_X", "C3_X", "Y")
############################################################
# generate indicators for X
############################################################
# Select one set of loading sizes and number of indicators
loading <- loading_size[1]
n_items <- num_loadings[1]
# Create loading vector (same loading across indicators) and find error_var
lambda <- rep(loading, n_items)
error_var <- 1 - loading^2
# Each observed indicator = lambda * eta_X + error
indicator_matrix <- sapply(1:n_items, function(i) {
lambda[i] * sim_data$X + rnorm(N, mean = 0, sd = sqrt(error_var))
})
# Each observed indicator = lambda * eta_X + error
indicator_matrix <- sapply(1:n_items, function(i) {
lambda[i] * data$X + rnorm(N, mean = 0, sd = sqrt(error_var))
})
# Convert to data frame
indicator_df <- as.data.frame(indicator_matrix)
colnames(indicator_df) <- paste0("X", 1:n_items)
# combine data
sim_data <- cbind.data.frame(sim_data,indicator_df)
# combine data
data <- cbind.data.frame(data,indicator_df)
View(data)
model <- rblimp(
data = sim_data,
burn = 10000,
iter = 20000,
seed = 91030,
latent = 'X_eta',
ordinal = 'C2 C3',
model = 'X_eta -> X1:X6;
Y ~ C2 C3 X_eta C2*X_eta C3*X_eta'
)
model <- rblimp(
data = data,
burn = 10000,
iter = 20000,
seed = 91030,
latent = 'X_eta',
ordinal = 'C2 C3',
model = 'X_eta -> X1:X6;
Y ~ C2 C3 X_eta C2*X_eta C3*X_eta'
)
version()
devtools::install_github("choi-phd/Firestar")
#For installing the package Firestar from github
library(devtools)
install.packages("devtools")
# Set your unique Personal Access Github Token
#Can get your access token or create a new one here
#https://github.com/settings/tokens
Sys.setenv(GITHUB_PAT = "your_new_token_here")
#Install Firestar
devtools::install_github("choi-phd/Firestar")
library(Firestar)
library(psych)
library(ggplot2)
library(readr)
library(rcompanion)
library(moments)
library(dplyr)
options(scipen=999)
load(file = "focal_total.rda")
?lm
# EXAMPLE 10.5 - FCS Multiple Imputation for Mediation w Nested Bootstrap
# requires blimp installation from www.appliedmissingdata.com/blimp
# remotes::install_github('blimp-stats/rblimp')
# remotes::update_packages('rblimp')
library(lavaan)
library(mitml)
library(rblimp)
data_url <- "https://raw.githubusercontent.com/craigenders/amd-book-examples/main/Data/pain.rda"
load(gzcon(url(data_url, open = "rb")))
impute <- rblimp_fcs(
data = pain,
ordinal = 'pain',
variables = 'anxiety stress control depress interfere pain',
seed = 90291,
burn = 10000,
iter = 10000,
nimps = 100,
chains = 100)
output(impute)
# mitml list
implist <- as.mitml(impute)
lavaan_model <- '
interfere ~ apath*pain
depress   ~ bpath*interfere + cpath*pain
indirect := apath*bpath
total := cpath + (apath*bpath)
'
# fit model with ml and latent response scores
pooled <- sem.mi(lavaan_model, data = implist, estimator = "ml")
install.packages("lavaan.mi")
library(lavaan.mi)
# fit model with ml and latent response scores
pooled <- sem.mi(lavaan_model, data = implist, estimator = "ml")
summary(pooled, standardized = T, fit = T)
# bootstrap settings
B <- 5   # number of bootstrap samples
param_names <- c("apath", "bpath", "cpath", "indirect", "total")
# storage
boot_estimates <- matrix(NA, nrow = length(implist) * B, ncol = length(param_names))
boot_estimates
colnames(boot_estimates) <- param_names
boot_estimates
# nested bootstrap over imputations
row_index <- 1
?seq_along
seq_along(implist)
implist
View(implist)
as.data.frame(implist[[m]])
m=1
as.data.frame(implist[[m]])
# nested bootstrap over imputations
row_index <- 1
for (m in seq_along(implist)) {
data_m <- as.data.frame(implist[[m]])
n <- nrow(data_m)
for (b in 1:B) {
# draw bootstrap sample
boot_idx <- sample(seq_len(n), size = n, replace = TRUE)
boot_data <- data_m[boot_idx, ]
# fit lavaan model to bootstrap sample
fit <- try(sem(lavaan_model, data = boot_data, se = "none"), silent = TRUE)
if (!inherits(fit, "try-error")) {
est <- parameterEstimates(fit)
# extract by parameter labels
boot_estimates[row_index, ] <- c(
est$est[est$label == "apath"],
est$est[est$label == "bpath"],
est$est[est$label == "cpath"],
est$est[est$label == "indirect"],
est$est[est$label == "total"]
)
}
row_index <- row_index + 1
}
}
# compute pooled bootstrap estimates & CIs
bootstrap_results <- data.frame(
parameter = param_names,
est    = colMeans(boot_estimates, na.rm = TRUE),
lower  = apply(boot_estimates, 2, quantile, probs = 0.025, na.rm = TRUE),
upper  = apply(boot_estimates, 2, quantile, probs = 0.975, na.rm = TRUE)
)
print(bootstrap_results)
library(mvtnorm)
library(dplyr)
library(lavaan)
library(rblimp)
options(scipen=999)
runfromshell <- F
# import arguments from unix shell script or specify manually in else{}
if(runfromshell){
runvars <- commandArgs(T)
runoncluster <- as.integer(runvars[1])
dirname <- (runvars[2])
filename <- (runvars[3])
cat <- as.numeric(runvars[4])
group_prob <- as.numeric(runvars[5])
rsq_prod <- as.numeric(runvars[6])
N <- as.numeric(runvars[7])
loading <- as.numeric(runvars[8])
n_items <- as.numeric(runvars[9])
rep <- as.numeric(runvars[10])
seed <- as.numeric(runvars[11])
}else{
runoncluster <- 0
dirname <- "C:/Users/remus/OneDrive/Documents/GitHub/latent_interaction/sim_latent_interaction"
# dirname <- "~/Documents/GitHub/latent_interaction/sim_latent_interaction"
filename<- "g1prod03N350load5item6"
cat <- 2
group_prob <- 1  # 1:3
rsq_prod <- 0.03    # 0, 0.03, 0.07
N <- 350      # seq(100,400, by = 50), 500, 1000
loading <- .5   # .5 or .8
n_items <- 6    # 6 or 12
rep <- 1
seed <- 75080
}
# set paths
if(runoncluster == 1){setwd(dirname)} else if(runoncluster == 0){setwd(paste0(dirname))}
############################################################
# Select group probabilities based on category condition
############################################################
group_probs3 <- rbind(c(.34, .33, .33),
c(.40, .40, .20),
c(.60, .20, .20))
group_probs2 <- rbind(c(.50,.50),
c(.60,.40),
c(.80,.20))
if(cat == 2){
probs <- group_probs2[group_prob,]
bin <- T
} else {
probs <- group_probs3[group_prob,]
bin <- F
}
############################################################
# Pull population parameters
############################################################
# Load parameters file
load(file = paste0(dirname,"/misc/parameter_values.rda"))
name <- paste0("cat",cat,"_prob",group_prob,"_rsq",rsq_prod,"_items",
n_items,"_loading",loading)
# Moderation parameters
mod_parameters <- parameter_values[[name]]$mod_parameters
# Multigroup parameters
group_parameters <- parameter_values[[name]]$group_parameters
# Covariance matrix and mean vector per group
moments_G1 <- parameter_values[[name]]$G1
moments_G2 <- parameter_values[[name]]$G2
if(bin == F){moments_G3 <- parameter_values[[name]]$G3}
# sum score parameters
sum_score_params <- parameter_values[[name]]$sum_score_parameters
N <- 100000
ng <- N * probs
g1dat <- cbind(1,rmvnorm(ng[1], as.vector(moments_G1$mean), as.matrix(moments_G1$covariance)))
g2dat <- cbind(2,rmvnorm(ng[2], as.vector(moments_G2$mean), as.matrix(moments_G2$covariance)))
if (bin == F){
g3dat <- cbind(3,rmvnorm(ng[3], as.vector(moments_G3$mean), as.matrix(moments_G3$covariance)))
dat <- as.data.frame(rbind(g1dat,g2dat,g3dat))
names(dat) <- c('G',paste0('X',1:n_items),paste0('Y',1:n_items))
} else {
dat <- as.data.frame(rbind(g1dat,g2dat))
names(dat) <- c('G',paste0('X',1:n_items),paste0('Y',1:n_items))
}
model <- '
X =~ X1 + X2 + X3 + X4 + X5 + X6
Y =~ Y1 + Y2 + Y3 + Y4 + Y5 + Y6
Y ~ X
Y ~ 1   # same intercept across groups
'
fit <- sem(model, data = dat, group = "G", group.equal = "loadings", std.lv = TRUE)
summary(fit)
model <- '
X =~ X1 + X2 + X3 + X4 + X5 + X6
Y =~ Y1 + Y2 + Y3 + Y4 + Y5 + Y6
Y ~ X
'
fit <- sem(model, data = dat, group = "G", group.equal = "loadings", std.lv = TRUE)
summary(fit)
N
g1dat <- cbind(1,rmvnorm(ng[1], as.vector(moments_G1$mean), as.matrix(moments_G1$covariance)))
g2dat <- cbind(2,rmvnorm(ng[2], as.vector(moments_G2$mean), as.matrix(moments_G2$covariance)))
if (bin == F){
g3dat <- cbind(3,rmvnorm(ng[3], as.vector(moments_G3$mean), as.matrix(moments_G3$covariance)))
dat <- as.data.frame(rbind(g1dat,g2dat,g3dat))
names(dat) <- c('G',paste0('X',1:n_items),paste0('Y',1:n_items))
} else {
dat <- as.data.frame(rbind(g1dat,g2dat))
names(dat) <- c('G',paste0('X',1:n_items),paste0('Y',1:n_items))
}
model <- '
X =~ X1 + X2 + X3 + X4 + X5 + X6
Y =~ Y1 + Y2 + Y3 + Y4 + Y5 + Y6
Y ~ X
'
fit <- sem(model, data = dat, group = "G", group.equal = "loadings", std.lv = TRUE)
summary(fit)
fit <- sem(model, data = dat, group = "G", std.lv = TRUE)
summary(fit)
View(group_parameters)
fit <- sem(model, data = dat, group = "G", group.equal = "loadings", std.lv = TRUE)
summary(fit)
